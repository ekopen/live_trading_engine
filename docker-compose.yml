services:
  # data storage
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    environment:
      CLICKHOUSE_USER: ${CLICKHOUSE_USERNAME}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "clickhouse-client --query 'SELECT 1' --user=${CLICKHOUSE_USERNAME} --password=${CLICKHOUSE_PASSWORD} || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # streaming data
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      # Single broker in KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Listeners (internal for Docker, external for consumers)
      KAFKA_LISTENERS: "INTERNAL://0.0.0.0:19092,EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:19092,EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"

      # Broker basics
      KAFKA_BROKER_ID: 1
      CLUSTER_ID: "CQdFOKLdQ8Si0WWDeEUgGg"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # Single-node replication factors
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1

      # Memory
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms128M"

      # Retention/logging (your values kept)
      KAFKA_LOG_RETENTION_MINUTES: 15
      KAFKA_LOG_SEGMENT_BYTES: 77428800
      KAFKA_LOG_RETENTION_BYTES: 268435456
      KAFKA_DELETE_TOPIC_ENABLE: "true"

    volumes:
      - kafka_data:/var/lib/kafka/data
    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:19092 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # modules
  market_data_stream:
    build:
      context: .
      dockerfile: ./market_data_stream/Dockerfile
    container_name: market_data_stream
    env_file: .env
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./common/logs/market_data_stream:/app/logs
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  market_data_storage:
    build:
      context: .
      dockerfile: ./market_data_storage/Dockerfile
    container_name: market_data_storage
    env_file: .env
    depends_on:
      clickhouse:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./common/logs/market_data_storage:/app/logs
      - ./market_data_storage/parquet_data:/app/parquet_data
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  ml_trading_strategies:
    build:
      context: .
      dockerfile: ./ml_trading_strategies/Dockerfile
    container_name: ml_trading_strategies
    env_file: .env
    depends_on:
      clickhouse:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./common/logs/ml_trading_strategies:/app/logs
      - ./ml_trading_strategies/models:/app/models
      - ./ml_trading_strategies/feature_data:/app/feature_data
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  systematic_trading:
    build:
      context: .
      dockerfile: ./systematic_trading/Dockerfile
    container_name: systematic_trading
    env_file: .env
    depends_on:
      clickhouse:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./common/logs/systematic_trading:/app/logs
      - ./systematic_trading/models:/app/models
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # downstream monitoring
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./common/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USERNAME}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
      GF_SECURITY_ALLOW_EMBEDDING: "true"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Viewer"
    ports:
      - "3000:3000"
    depends_on:
      prometheus:
        condition: service_started
    volumes:
      - grafana_data:/var/lib/grafana
      - ./common/provisioning:/etc/grafana/provisioning
      - ./common/dashboards:/var/lib/grafana/dashboards
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  node_exporter:
    image: prom/node-exporter:latest
    container_name: node_exporter
    ports:
      - "9100:9100"
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
      
  kafka_exporter:
    image: danielqsj/kafka-exporter
    container_name: kafka_exporter
    ports:
      - "9308:9308"
    environment:
      KAFKA_BROKER: kafka:19092
    command:
      - "--kafka.server=kafka:19092"
    depends_on:
      - kafka
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
        
networks:
  default:
    name: trading_net

volumes:
  clickhouse_data:
  kafka_data:
  grafana_data:
  prometheus_data:

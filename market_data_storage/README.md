# Market Data Storage  

This is part of my overarching **Live Trading Engine** project. Visit [www.erickopen.com](http://www.erickopen.com) to see my projects running live and to view comprehensive documentation.  

## Overview  
Captures market data from a Kafka consumer and stores it in a **ClickHouse** database, with older data archived to **AWS**. Downstream applications use this data to train and power trading algorithms.  

## Details  
- Creates a **Kafka consumer** that subscribes to the topic generated by the **Market Data Stream** module, which provides tick-level market data for multiple cryptocurrencies.  
- Continuously writes new data from the consumer to a **ClickHouse** database using batch inserts. A downsampled, minute-level tick table is also automatically generated.  
- Data retention in ClickHouse is capped at seven days. Older data is periodically archived as **Parquet** files, uploaded to **AWS**, and then deleted from local storage.  
- Metrics such as data ingestion rate, processing lag, and WebSocket latency are recorded in ClickHouse for system monitoring.  
- The downsampled market data generated in this module is used to train algorithms in the **ML Trading Strategies** module and to provide feature data for the **Systematic Trading** module.  

## Future Improvements  
- Transition from ClickHouse batch inserts to the **ClickHouse Kafka engine** for more efficient, real-time ingestion.  
